{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e325048e-9111-4bff-ae13-562a43bbf89d",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 40px; margin-top: 0;\">\n",
    "    <div style=\"flex: 0 0 auto; margin-left: 0; margin-bottom: 0; margin-top: 0;\">\n",
    "        <img src=\"./pics/UCSD Logo.png\" alt=\"UCSD Logo\" style=\"width: 179px; margin-bottom: 0px; margin-top: 20px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/ndp-logo.png\" alt=\"NDP Logo\" style=\"width: 200px; margin-bottom: 0px;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 0 0 auto; margin-left: auto; margin-bottom: 0; margin-top: 20px;\">\n",
    "        <img src=\"./pics/sdsc-logo.png\" alt=\"SDSC Logo\" style=\"width: 200px; margin-bottom: 0px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<h1 style=\"text-align: center; font-size: 48px; margin-top: 0;\">Onboarding Module</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ce234-fbac-48de-ac64-fd27ff458751",
   "metadata": {},
   "source": [
    "This module is designed to provide an onboarding experience and introduce you to working with NDP Modules.\n",
    "\n",
    "The problem and data used in this demo module were originally developed as part of the [Big Data Specialization](https://www.coursera.org/specializations/big-data#courses) offered by UC San Diego on Coursera.\n",
    "\n",
    "## The Data\n",
    "\n",
    "The file `daily_weather.csv` is a comma-separated file that contains weather data.  This data comes from a weather station located in San Diego, California.  The weather station is equipped with sensors that capture weather-related measurements such as air temperature, air pressure, and relative humidity.  Data was collected for a period of three years, from September 2011 to September 2014, to ensure that sufficient data for different seasons and weather conditions is captured.\r\n",
    "\r\n",
    "Sensor measurements from the weather station were captured at one-minute intervals.  These measurements were then processed to generate values to describe daily weather. Since this dataset was created to classify low-humidity days vs. non-low-humidity days (that is, days with normal or high humidity), the variables included are weather measurements in the morning, with one measurement, namely relatively humidity, in the afternooy.\r\n",
    "\r\n",
    "Each row in daily_weather.csv captures weather data for a separate day.  Each row, or sample, consists of the following variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118816e-d46e-4181-8746-abe0d6c1c1b5",
   "metadata": {},
   "source": [
    "| Variable                  | Description                                                | Unit of Measure           |\n",
    "|---------------------------|------------------------------------------------------------|---------------------------|\n",
    "| number                    | Unique number for each row                                 | NA                        |\n",
    "| air_pressure_9am          | Air pressure averaged over a period from 8:55am to 9:04am | hectopascals              |\n",
    "| air_temp_9am             | Air temperature averaged over a period from 8:55am to 9:04am | degrees Fahrenheit        |\n",
    "| avg_wind_direction_9am    | Wind direction averaged over a period from 8:55am to 9:04am | degrees, 0 = North, increasing clockwise |\n",
    "| avg_wind_speed_9am       | Wind speed averaged over a period from 8:55am to 9:04am    | miles per hour            |\n",
    "| max_wind_direction_9am    | Wind gust direction averaged over a period from 8:55am to 9:04am | degrees, 0 = North, increasing clockwise |\n",
    "| max_wind_speed_9am       | Wind gust speed averaged over a period from 8:55am to 9:04am | miles per hour            |\n",
    "| rain_accumulation_9am     | Amount of rain accumulated in the 24 hours prior to 9am   | millimeters               |\n",
    "| rain_duration_9am         | Amount of time rain was recorded in the 24 hours prior to 9am | seconds                   |\n",
    "| relative_humidity_9am     | Relative humidity averaged over a period from 8:55am to 9:04am | percent               |\n",
    "| relative_humidity_3pm     | Relative humidity averaged over a period from 2:55pm to 3:04pm | percent               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72755a-0c59-4595-a491-81e8d1320b71",
   "metadata": {},
   "source": [
    "### The Task\n",
    "\n",
    "In this onboarding module, our goal is to predict whether a day is **humid** or not. The idea is to use the morning weather values to predict whether the day will be low-humidity or not based on the afternoon measurement of relatively humidity. We will define a **humid day** as one where humidity at 3 PM is at least 25%. We will not use the column *relative_humidity_9am* as an input to our model, since this variable is highly correlated with the humidity at 3pm. \n",
    "\n",
    "Before diving into model training, let's first explore our dataset.\n",
    "\n",
    "## Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b827d-78c3-47b8-be20-3b6b27be2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eabe88-4434-4aa5-9d62-9be90b534397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the data into a pandas df and drop the column 'number' since we don't have a use for it\n",
    "df = pd.read_csv(\"weather-station-measurements/daily_weather.csv\").drop(columns=['number'], errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50133cc6-e9e1-4c63-b43c-36a1762cca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our data, including a few rows and the number of columns and rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021a22b-b7a0-4357-b775-5e87f0f1c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display the summary statistics for each of the columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef0e9aa-96d0-416c-9d4e-c8f36f0acc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's look at the distribution of each of the columns\n",
    "\n",
    "num_cols = len(df.columns)\n",
    "num_rows = (num_cols // 3) + (num_cols % 3 > 0) \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, 3, figsize=(15, 4 * num_rows))\n",
    "axes = axes.flatten()  # Flatten to iterate easily\n",
    "\n",
    "# Create a histogram for each column\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(df[col].dropna(), kde=True, ax=axes[i], bins=30)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a636-00bf-44cc-8788-e422e8e6b966",
   "metadata": {},
   "source": [
    "# Predicting whether a day is humid or not\n",
    "\n",
    "Now that we took a look at our data, we will train a [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to predict whether a day can be considered humid or not, based on morning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a6201-bce6-4913-987e-f08fb3afc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop relative humidity at 9am since it's highly correlated to our target column\n",
    "X = df.drop(columns=['relative_humidity_3pm', 'relative_humidity_9am']) \n",
    "\n",
    "# We set a threshold of 25%. Any day with a humidity % higher than that, we consider it humid\n",
    "threshold = 24.99999\n",
    "y = (df[\"relative_humidity_3pm\"] > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5c946-3240-4cd1-bdb8-0d5d7bb433fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will impute the missing values with the median\n",
    "X = X.fillna(X.median())  \n",
    "y = y.fillna(y.median()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce4178-6044-4af2-bd1e-c53187539c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use a test size of 20% of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c36e2d1-5f68-4c38-9f66-05553102c69e",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14d5c1-2c50-4004-9894-3cc34604c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make predictions\n",
    "y_pred = clf.predict(X_test)# Evaluate the model\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a5af9-4c86-441f-8a7f-95e3d497f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our predictions with more detail with the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "cax = ax.matshow(cm, cmap=\"Blues\")\n",
    "\n",
    "plt.colorbar(cax)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, str(cm[i, j]), ha='center', va='center', color='black', fontsize=12)\n",
    "        \n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be5875-e737-40d5-8516-1d3442fd8736",
   "metadata": {},
   "source": [
    "### Can you build a better model? \n",
    "\n",
    "Inside this folder, create a new notebook (*File --> New --> Notebook*), name it `your-name.ipynb` and work on a new model to improve upon our current benchmark. You can experiment with different model types, adjust hyperparameters, or engineer new features to enhance performance.\n",
    "\n",
    "Once you have made improvements, copy your notebook to the shared folder so your team members can review it. Remember to keep the outputs so the rest of your team members can see your results. \n",
    "\n",
    "Once you have finished your work, remember to stop your server (*File --> Hub Control Panel --> Stop Server*)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
